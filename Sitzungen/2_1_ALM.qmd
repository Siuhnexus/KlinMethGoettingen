---
title: "Datenanalyse ALM"
author: "YH"
date: '2022-05-16'
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Activate packages
```{r}
library(ggplot2)
library(psych)
library(Hmisc)
library(car)
library(lmtest)
library(effectsize)
library(rcompanion)
```
### set working directory

Bitte anpassen, damit es für Sie passt. Am einfachsten erst die RMD Datei am Zielort speichern und von dort aus öffnen. 
Dann unter Session -> Set Working Directory -> To Source file location
Der Pfad erscheint unten in der Console. Dann über Strg c und Strg v hierher kopieren.
```{r}
setwd("~/Teaching/Master/Methoden_Klippt/Methoden Klippt 2022/Datenbeispiele/2_1")
```

### Daten einlesen

Auch hier bitte darauf achten, dass das Verzeichnis für die Dateil stimmt und die Datei auch tatsächlich in dem angegeben Ordner zu finden ist.
```{r}
dat_1 <- read.csv(file = "~/Teaching/Master/Methoden_Klippt/Methoden Klippt 2022/Datenbeispiele/2_1/Dat_VR_Anxiety_lm1.csv", header = TRUE, sep = ",", dec = ".", na.strings = "NA")

# Characterstrings als Faktoren definieren
dat_1$Gruppe <- as.factor(dat_1$Gruppe) 
dat_1$Gruppe <- factor(dat_1$Gruppe, levels = c("Warteliste", "in_sensu", "in_virtuo")) 

# Change berechnen

dat_1$Change <- dat_1$Post - dat_1$Pre

```

## Visuelle Analyse
Sollte immer gemacht werden-
```{r}

## Prä-Messung
ggplot(dat_1, aes(Gruppe, Pre)) + 
  geom_violin() + 
  geom_jitter(width = 0.3, height = 0, col = "grey", size = 0.5) +
  stat_summary(fun = mean, geom = "point", size = 2, col = "red")  +
  stat_summary(geom="errorbar", fun.data=mean_cl_normal, width=.1, col ="red")+
  ylim(0,40) +
  ylab("Score Anxiety") + 
  xlab("Treatment") +
  ggtitle("Belastung vor Behandlung")

## Post-Messung
ggplot(dat_1, aes(Gruppe, Post)) + 
  geom_violin() + 
  geom_jitter(width = 0.3, height = 0, col = "grey", size = 0.5) +
  stat_summary(fun = mean, geom = "point", size = 2, col = "red")  +
  stat_summary(geom="errorbar", fun.data=mean_cl_normal, width=.1, col ="red")+
  ylim(0,40) +
  ylab("Score Anxiety") + 
  xlab("Treatment") +
  ggtitle("Belastung nach Behandlung")

## Veraenderung
ggplot(dat_1, aes(Gruppe, Change)) + 
  geom_violin() + 
  geom_jitter(width = 0.3, height = 0, col = "grey", size = 0.5) +
  stat_summary(fun = mean, geom = "point", size = 2, col = "red")  +
  stat_summary(geom="errorbar", fun.data=mean_cl_normal, width=.1, col ="red")+
  ylim(-30,+10) +
  ylab("Absolute Change Score Anxiety") + 
  xlab("Treatment") +
  ggtitle("Veränderung Belastung Prä zu Post")

## Zusammenhang Pre-Werte und Post-Werte
ggplot(dat_1, aes(Pre, Post)) + 
  geom_point() + 
  geom_smooth(method = "lm") +
  facet_wrap(~Gruppe)+
  ylab("Post-Werte") + 
  xlab("Prä-Werte")+
  ggtitle("Zusammenhang Prä und Post pro Gruppe")
```

# Zu Grunde gelegtes statistisches Modell

Score Pre-Treatment und Behandlung sagen Score Post-Treatment vorher

## Analyse Schritt 1: Allgemeines lineares Modell anpassen

```{r}
# Zentrierung des kontinuierlichen Praediktors Pre-Wert
dat_1$Pre_c <- scale(dat_1$Pre, center = TRUE, scale = FALSE) # dient der besseren Interpretierbarkeit

# Modelldefinition
M1 <- lm(Post ~ Pre_c + Gruppe, data = dat_1)

# Schaetzung der Parameter
summary(M1)
```

## Überprüfung des Modells: Testung ob alle Prädiktoren in das Modell eingeschlossen werden sollten

Hierfür werden Modellvergleiche, sprich Varianzanalysen gerechnet. Jeder Prädiktor wird aus dem Gesamtmodell entfernt und es wird getestet, ob das Gesamtmodell besser als das Teilmodell ist.

```{r}
VA1 <- Anova(M1)
VA1

M1b <- lm(Post ~ Pre_c, data = dat_1)
M1c <- lm(Post ~ Gruppe, data = dat_1)
anova(M1b, M1)
anova(M1c, M1)
```
## Berechnung der Effektstärken = Varianzaufklärung für die einzelnen Prädiktoren
```{r}
eta_squared(VA1)
```
## Check 1: Unabhängigkeit der Prädiktoren

Das ALM nimmt an, dass die Prädiktoren unabhängig voneinander sind. Praktisch bedeutet dies, dass vorhandene Korrelationen eher gering sind. Hierfür werden am einfachsten Variance-Inflation_Factors VIF genommen. Diese sollten bei 1 liegen, ab 4 sollte überlegt werden, ob Prädiktoren entfernt oder miteinander verrechnet / integriert werden sollten. 

```{r}
vif(M1)
```
## Check 2: Analyse der Residuen

Das ALM nimmt an, dass die Fehler zufällig und unabhängig von den Prädiktoren sind (Annahme der Varianzhomogenität btw. Homoskedastizität). Wenn dies der Fall ist, dann sollten die Residuen zufällig und normalverteilt um den Wert von Null streuen. Ebenso sollten sich in einer Abbildung der Residuen und vorhergesagten Werte kein Zusammenhang und keine systematische Abweichung von Null zeigen. 
```{r}
## Verteilung der Residuen
densityPlot(M1$residuals)
plotNormalDensity(M1$residuals)

## Verteilung der Residuen in Abhängigkeit von vorhergesagten Werten
scatterplot(M1$residuals ~ M1$fitted.values)
scatterplot(rstandard(M1)~fitted(M1))

## Statistischer Test auf Homoskedastizität: Breusch-Pagan Test
bptest(M1)
```
## Check 3: Test auf Autokorrelation der Residuen

Das ALM geht davon aus, dass Messwerte unabhängig voneinander sind. Wenn diese abhängig voneinander sein sollten, dann nimmt das ALM an, dass diese Abhängigkeit durch die Prädiktoren im Modell erklärt wird. Um zu untersuchen, ob dies der Fall ist, wird analysiert ob die Residuen miteinander korreliert sind. Dies sollte nicht der Fall sein. Wenn diese korreliert sind, dann müssen wir das Modell so erweitern, dass diese Abhängigkeit durch das erweiterte Modell erklärt wird. (Siehe Multi-level)

```{r}
durbinWatsonTest(M1) # Test für eine Autokorrelation 1.Ordnung
```
## Einflussreiche Ausreißer

Cook's distance ist ein gutes Maß zur Ermittlung zu einflussreicher Ausreißer. Die Werte der einzelnen Fälle sollte nicht größer sein als 4/(N-k-1). Hier im Beispiel N=146 => Werte > 0,0273

```{r}
cd <- cooks.distance(M1)
#View(cd)
plot(M1,4)
hist(cd)
```




# Zu Grunde gelegtes statistisches Modell

Behandlung und Score-Pre-Treatment sagen Veränderung des Ängstlichkeit-Scores voraus.

## Analyse Schritt 1: Allgemeines lineares Modell anpassen

```{r}

```

## Überprüfung des Modells: Testung ob alle Prädiktoren in das Modell eingeschlossen werden sollten

Hierfür werden Modellvergleiche, sprich Varianzanalysen gerechnet. Jeder Prädiktor wird aus dem Gesamtmodell entfernt und es wird getestet, ob das Gesamtmodell besser als das Teilmodell ist.

```{r}

```

## Berechnung der Effektstärken = Varianzaufklärung für die einzelnen Prädiktoren
```{r}

```

## Check 1: Unabhängigkeit der Prädiktoren

Das ALM nimmt an, dass die Prädiktoren unabhängig voneinander sind. Praktisch bedeutet dies, dass vorhandene Korrelationen eher gering sind. Hierfür werden am einfachsten Variance-Inflation_Factors VIF genommen. Diese sollten bei 1 liegen, ab 4 sollte überlegt werden, ob Prädiktoren entfernt oder miteinander verrechnet / integriert werden sollten. 

```{r}

```
## Check 2: Analyse der Residuen

Das ALM nimmt an, dass die Fehler zufällig und unabhängig von den Prädiktoren sind (Annahme der Varianzhomogenität btw. Homoskedastizität). Wenn dies der Fall ist, dann sollten die Residuen zufällig und normalverteilt um den Wert von Null streuen. Ebenso sollten sich in einer Abbildung der Residuen und vorhergesagten Werte kein Zusammenhang und keine systematische Abweichung von Null zeigen. 

```{r}

```

## Check 3: Test auf Autokorrelation der Residuen

Das ALM geht davon aus, dass Messwerte unabhängig voneinander sind. Wenn diese abhängig voneinander sein sollten, dann nimmt das ALM an, dass diese Abhängigkeit durch die Prädiktoren im Modell erklärt wird. Um zu untersuchen, ob dies der Fall ist, wird analysiert ob die Residuen miteinander korreliert sind. Dies sollte nicht der Fall sein. Wenn diese korreliert sind, dann müssen wir das Modell so erweitern, dass diese Abhängigkeit durch das erweiterte Modell erklärt wird. (Siehe Multi-level)

```{r}

```


