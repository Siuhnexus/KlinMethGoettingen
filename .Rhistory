impacts = list(
#list(impact = 10, timePosition = 10)
)
# Lineare Abhängigkeiten
# Syntax: Das Ganze ist eine Liste von Listen, wobei jede innere Liste einen Spline abbildet.
#         Dabei hat jeder Spline die gewünschte Steigung im ersten Argument
#         und den Zeitraum, in dem der Zusammenhang vorhanden ist, als Vektor im zweiten
#         Argument. Wie die Argumente heißen ist vollkommen egal, die Reihenfolge zählt.
linears = list(
list(beta = 1, timeFrame = 1:21),
list(beta = -1, timeFrame = 21:31),
list(beta = -2, timeFrame = 31:36),
list(beta = 0.5, timeFrame = 36:50)
)
# Logistische Abhängigkeiten
logistics = list()
# Residualstreuung
sres = 1
# Arimaprozess
arcor = 0.85
data = generateFromModel(n, b0, impacts, linears, logistics, sres, arcor)
ggplot(data, aes(x = time, y = value)) +
geom_line()
library(ggplot2)
ggplot(data, aes(x = time, y = value)) +
geom_line()
data = read.csv("~/../Downloads/titanic.csv")
View(data)
View(data)
"Test" + 1:10
paste("Test", 1:10, sep="")
?paste
"Test" + as.character(1:10)
as.character(1:10)
paste0("Test", 1:10)
data = data.frame(id = 1:100)
data[[paste0("Schlaf_Tag", 1:14)]] = rnorm(100)
data$paste0("Schlaf_Tag", 1:14) = rnorm(100)
data$paste0("Schlaf_Tag", 1) = rnorm(100)
data$(paste0("Schlaf_Tag", 1)) = rnorm(100)
data[[paste0("Schlaf_Tag", 1)]] = rnorm(100)
Schlaf_Tag1:Schlaf_Tag14
setGeneric("+", function(x, y) {})
setGeneric("%+%", function(x, y) {if(is.numeric(x) & is.numeric(y)) {return(x + y)} else {return paste0(x, y)}})
setGeneric("%+%", function(x, y) {if(is.numeric(x) & is.numeric(y)) {return(x + y)} else {return(paste0(x, y))}})
"Test" %+% 1:13
1 %+% 3
setGeneric("++", function(x, y) {if(is.numeric(x) & is.numeric(y)) {return(x + y)} else {return(paste0(x, y))}})
1 ++ 1:13
as.character(1:13) ++ 1
as.character(1:13) +++ 1
as.character(1:13)++                 1
1 ++ as.character(1:13)
data$paste0("i", "d")
data $ paste0("i", "d")
data $ paste0("id")
??pivot_wider
a=3
b=5
c=10
time=1:15
s1 <- min(time, a)
s1 <- min(time, rep(a, length(time)))
?min
pmin(time, a)
s1 <- pmin(time, a)
s2 <- pmin(pmax(time – a, 0), b – a)
s2 <- pmin(pmax(time - a, 0), b - a)
s3 <- pmax(time – b, 0)
s3 <- pmax(time - b, 0)
nhanes <- (nhanes)
nhanes2 <- nhanes2
library(mice)
nhanes <- (nhanes)
nhanes2 <- nhanes2
# do default multiple imputation on a numeric matrixm m=10 imputations
imp <- mice(nhanes, m=10, method = "pmm")
# pmm = predictive mean matching = default
## Zeige Predictormatrix
imp
# list the actual imputations for BMI
imp$imp$bmi
# show first completed data matrix
complete(imp)
# imputation on mixed data with a different method per column
imp2 <- mice(nhanes2, meth=c('sample','pmm','logreg','norm'))
# Definiere Modell für alle Datensätze
fit1 <- with(data=imp,exp=lm(chl~age + bmi + hyp))
# Definiere alternatives Modell für alle Datens
fit2 <- with(data=imp,exp=lm(chl~age + hyp))
# Ergebnisse der Modellschätzungen in den einzelnen Datensätzen
summary(fit1)
summary(fit2)
fit1.pooled <- pool(fit1)
fit2.pooled <-pool(fit2)
# Modellzusammenfassungen
summary(fit1.pooled)
summary(fit2.pooled)
# Wald t-Test
summary(D1(fit1, fit2))
# Hinweis: riv = relative increase in variance
# likelihood ratio Test
summary(D3(fit1, fit2))
?D2
?strsplit
1++
2
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W*")
words2 = strsplit(title2, "\\W*")
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1[i] %in% words2) {
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W*")
words2 = strsplit(title2, "\\W*")
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1[i] %in% words2) {
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
print(matchingCount / wordCount1)
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
print(i)
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W*")
words2 = strsplit(title2, "\\W*")
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1[i] %in% words2) {
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
print("MatchingCount")
print(matchingCount / wordCount1)
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
print(i)
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W*")
words2 = strsplit(title2, "\\W*")
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1[i] %in% words2) {
print("increased")
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
print(i)
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W*")
words2 = strsplit(title2, "\\W*")
print(words1)
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1[i] %in% words2) {
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
print(i)
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W+")
words2 = strsplit(title2, "\\W+")
print(words1)
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1[i] %in% words2) {
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
print(i)
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W+")[[1]]
words2 = strsplit(title2, "\\W+")[[1]]
print(words1)
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1 %in% words2) {
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
print(i)
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W+")[[1]]
words2 = strsplit(title2, "\\W+")[[1]]
print(words1)
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1[i] %in% words2) {
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
print(i)
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W+")[[1]]
words2 = strsplit(title2, "\\W+")[[1]]
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1[i] %in% words2) {
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
print(i)
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich haben kann")
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W+")[[1]]
words2 = strsplit(title2, "\\W+")[[1]]
wordCount1 = length(words1)
matchingCount = 0
for (i in 1:wordCount1) {
if (words1[i] %in% words2) {
matchingCount = matchingCount + 1
}
}
if(matchingCount / wordCount1 < sameWordsRatio) {
return(FALSE)
}
if(sameLastWords > 0) {
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate(Testtitel der es nicht haben hat", "Testtitel, der es in sich hat")
probablyDuplicate("Testtitel der es nicht haben hat", "Testtitel, der es in sich hat")
probablyDuplicate("Testtitel der es nicht in haben hat", "Testtitel, der es in sich hat")
probablyDuplicate("Testtitel der es nicht in sich haben hat", "Testtitel, der es in sich hat")
probablyDuplicate("Testtitel der es nicht in haben hat", "Testtitel, der es in sich hat")
wordsMatchingRatio = function(wordsToMatch, wordsList) {
wordCount = length(wordsToMatch)
matchingCount = 0
for (i in 1:wordCount) {
if (wordsToMatch[i] %in% wordsList) {
matchingCount = matchingCount + 1
}
}
return(matchingCount / wordCount)
}
probablyDuplicate = function(title1, title2, sameLastWords = 1, sameWordsRatio = .75) {
words1 = strsplit(title1, "\\W+")[[1]]
words2 = strsplit(title2, "\\W+")[[1]]
if(wordsMatchingRatio(words1, words2) < sameWordsRatio ||
wordsMatchingRatio(words2, words1) < sameWordsRatio) {
return(FALSE)
}
if(sameLastWords > 0) {
wordCount1 = length(words1)
wordCount2 = length(words2)
for (i in 1:sameLastWords) {
if (words1[wordCount1 + 1 - i] != words2[wordCount2 + 1 - i]) {
return(FALSE)
}
}
}
return(TRUE)
}
probablyDuplicate("Testtitel der es nicht in haben hat", "Testtitel, der es in sich hat")
probablyDuplicate("Testtitel der es nicht in sich haben hat", "Testtitel, der es in sich hat")
probablyDuplicate("Testtitel der es nicht haben hat", "Testtitel, der es in sich hat")
probablyDuplicate("Testtitel, der es in sich hat", "Testtitel der es nicht in sich hat")
temp = dang
findDuplicates = function(data, titleCol, ofTitle = NA) {
print(eval(titleCol))
}
findDuplicates([], dang)
findDuplicates(list(), dang)
findDuplicates = function(data, titleCol, ofTitle = NA) {
print(titleCol)
}
findDuplicates(list(), dang)
findDuplicates = function(data, titleCol, ofTitle = NA) {
print(data[[titleCol]])
}
findDuplicates(data.frame(dang=1:5), dang)
findDuplicates = function(data, titleCol, ofTitle = NA) {
print(data[titleCol])
}
findDuplicates(data.frame(dang=1:5), dang)
str(dang)
deparse(dang)
substitute(dang)
findDuplicates = function(data, titleCol, ofTitle = NA) {
print(data[deparse(titleCol)])
}
findDuplicates(data.frame(dang=1:5), dang)
findDuplicates = function(data, titleCol, ofTitle = NA) {
print(data[deparse(substitute(titleCol))])
}
findDuplicates(data.frame(dang=1:5), dang)
findDuplicates = function(data, titleCol, ofTitle = NA) {
print(data[[deparse(substitute(titleCol))]])
}
findDuplicates(data.frame(dang=1:5), dang)
# Daten laden
dat1 <- dat.raudenbush1985
dat1$setting <- as.factor(dat1$setting)
dat1$tester <- as.factor(dat1$tester)
### meta-analysis using a fixed-effects model
resf <- rma.uni(yi, vi, method= "FE", data=dat1)
resf
### random-effects model
resr <- rma.uni(yi, vi, data=dat1)
resr
####### with moderators
random_mods1 <- rma(yi, vi, mods = ~ weeks + setting + tester, data=dat1, method = "ML")
random_mods1
random_mods1b <- rma(yi, vi, mods = ~ setting + tester, data=dat1, method ="ML")
random_mods1b
random_mods1c <- rma(yi, vi, mods = ~ weeks, data=dat1, method ="ML")
random_mods1c
anova.rma(random_mods1, random_mods1b)
anova.rma(random_mods1, random_mods1c)
# install.packages("metafor")
library(metafor)
# Daten laden
dat1 <- dat.raudenbush1985
dat1$setting <- as.factor(dat1$setting)
dat1$tester <- as.factor(dat1$tester)
### meta-analysis using a fixed-effects model
resf <- rma.uni(yi, vi, method= "FE", data=dat1)
resf
### random-effects model
resr <- rma.uni(yi, vi, data=dat1)
resr
####### with moderators
random_mods1 <- rma(yi, vi, mods = ~ weeks + setting + tester, data=dat1, method = "ML")
random_mods1
random_mods1b <- rma(yi, vi, mods = ~ setting + tester, data=dat1, method ="ML")
random_mods1b
random_mods1c <- rma(yi, vi, mods = ~ weeks, data=dat1, method ="ML")
random_mods1c
anova.rma(random_mods1, random_mods1b)
anova.rma(random_mods1, random_mods1c)
plot(influence(random_mods1))
?funnel
library(metafor)
?funnel
?plot
?cex
??cex
?graphics
?scatterplot
?plot
?funnel
?regtest
# Daten laden
dat1 <- dat.raudenbush1985
dat1$setting <- as.factor(dat1$setting)
dat1$tester <- as.factor(dat1$tester)
# install.packages("metafor")
library(metafor)
# Daten laden
dat1 <- dat.raudenbush1985
dat1$setting <- as.factor(dat1$setting)
dat1$tester <- as.factor(dat1$tester)
### meta-analysis using a fixed-effects model
resf <- rma.uni(yi, vi, method= "FE", data=dat1)
resf
### random-effects model
resr <- rma.uni(yi, vi, data=dat1)
resr
states = ["a1", "a2", "a3", "a4"]
states = list("a1", "a2", "a3", "a4")
as.numeric(states)
as.numeric(as.factor(states))
as.numeric(data.frame(states = states))
df = data.frame(states = states)
df = data.frame(states=c("a1", "a2", "a3"))
as.numeric(df$states)
df$states = as.factor(df$states)
setwd("C:/Users/bente/Documents/Studium/BachelorPsychologie/Projekte/KlinMethGoettingen")
?round
